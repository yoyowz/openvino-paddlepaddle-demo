{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba0d9296-7fa6-4025-aedf-d2a19b05ff0d",
   "metadata": {},
   "source": [
    "# PaddleOCR with OpenVINO\n",
    "\n",
    "This demo shows how to run PaddleOCR (Lite) model on OpenVINO natively. Instead of exporting the PaddlePaddle model to ONNX and then create the Intermediate Representation (IR) format through OpenVINO optimizer, we can now read direct from the Paddle Model without any conversions.\n",
    "\n",
    "Authors: \n",
    "Zhuo Wu, PhD (OpenVINO Edge AI Software Evangelist - Intel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5a53f7-e1c5-4aca-879f-da2dd081b989",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run Paddle Detection with OpenVINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9486a04-b8bb-4bf5-9e13-845f2143a71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "import sys\n",
    "import json\n",
    "import urllib.request\n",
    "import cv2\n",
    "import numpy as np\n",
    "import paddle\n",
    "import math\n",
    "import time\n",
    "import collections\n",
    "\n",
    "from openvino.inference_engine import IENetwork, IECore, ExecutableNetwork\n",
    "from IPython import display\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import copy\n",
    "\n",
    "import logging\n",
    "import imghdr\n",
    "from shapely.geometry import Polygon\n",
    "import pyclipper\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "import notebook_utils as utils\n",
    "from pre_post_processing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e541150c-0f98-41c6-a97c-97acb26efd2f",
   "metadata": {},
   "source": [
    "### Load the Network for Paddle Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9c5c83a-961c-4d98-8b20-5e96c8ef71f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_model_dir = \"./inference/ch_ppocr_mobile_v2.0_det_infer\"\n",
    "det_model_file_path = det_model_dir + \"/inference.pdmodel\"\n",
    "det_params_file_path = det_model_dir + \"/inference.pdiparams\"\n",
    "\n",
    "det_ie = IECore()\n",
    "det_net = det_ie.read_network(det_model_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec5c940-626c-4cf7-a90f-833200969846",
   "metadata": {},
   "source": [
    "### Load the Network for Paddle Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89c0a07a-8186-47b5-ad95-f104a84d13d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_model_dir = \"./inference/ch_ppocr_mobile_v2.0_rec_infer\"\n",
    "rec_model_file_path = rec_model_dir + \"/inference.pdmodel\"\n",
    "rec_params_file_path = rec_model_dir + \"/inference.pdiparams\"\n",
    "\n",
    "rec_ie = IECore()\n",
    "rec_net = rec_ie.read_network(rec_model_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573a1a11-faec-41af-bf43-08b90d28cec3",
   "metadata": {},
   "source": [
    "### Preprocessing and post processing image functions for text detection and recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93bc8364-109b-4a32-b12b-bcb85f23b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(input_image, size):\n",
    "    img = cv2.resize(input_image, (size,size))\n",
    "    img = np.transpose(img, [2,0,1]) / 255\n",
    "    img = np.expand_dims(img, 0)\n",
    "    ##NormalizeImage: {mean: [0.485, 0.456, 0.406], std: [0.229, 0.224, 0.225], is_scale: True}\n",
    "    img_mean = np.array([0.485, 0.456,0.406]).reshape((3,1,1))\n",
    "    img_std = np.array([0.229, 0.224, 0.225]).reshape((3,1,1))\n",
    "    img -= img_mean\n",
    "    img /= img_std\n",
    "    return img.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "409b1cfc-07b4-484b-b8da-5dbdcdfcfbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_text_det_res(dt_boxes, img_path):\n",
    "    #src_im = cv2.imread(img_path)\n",
    "    src_im = img_path\n",
    "    for box in dt_boxes:\n",
    "        box = np.array(box).astype(np.int32).reshape(-1, 2)\n",
    "        cv2.polylines(src_im, [box], True, color=(255, 255, 0), thickness=2)\n",
    "    return src_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9329d709-14bc-45aa-a1d7-d0d6d608933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess for Paddle Recognition\n",
    "def resize_norm_img(img, max_wh_ratio):\n",
    "        rec_image_shape = [3, 32, 320]\n",
    "        imgC, imgH, imgW = rec_image_shape\n",
    "        assert imgC == img.shape[2]\n",
    "        character_type = \"ch\"\n",
    "        if character_type == \"ch\":\n",
    "            imgW = int((32 * max_wh_ratio))\n",
    "        h, w = img.shape[:2]\n",
    "        ratio = w / float(h)\n",
    "        if math.ceil(imgH * ratio) > imgW:\n",
    "            resized_w = imgW\n",
    "        else:\n",
    "            resized_w = int(math.ceil(imgH * ratio))\n",
    "        resized_image = cv2.resize(img, (resized_w, imgH))\n",
    "        resized_image = resized_image.astype('float32')\n",
    "        resized_image = resized_image.transpose((2, 0, 1)) / 255\n",
    "        resized_image -= 0.5\n",
    "        resized_image /= 0.5\n",
    "        padding_im = np.zeros((imgC, imgH, imgW), dtype=np.float32)\n",
    "        padding_im[:, :, 0:resized_w] = resized_image\n",
    "        return padding_im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d3695c-42c3-43d3-8472-9f16913182bf",
   "metadata": {},
   "source": [
    "### Main processing function for PaddleOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de5b68ee-bd25-4dd8-9e87-3fe6971c6e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define main function for PaddleOCR\n",
    "def run_paddle_ocr(source=0, flip=False, use_popup=False):\n",
    "    # create video player to play with target fps\n",
    "    player = utils.VideoPlayer(source=source, flip=flip, fps=30)\n",
    "    \n",
    "    #Start video capturing\n",
    "    player.start()\n",
    "    try:\n",
    "        if use_popup:\n",
    "            title = \"Press ESC to Exit\"\n",
    "            cv2.namedWindow(winname=title, flags=cv2.WINDOW_NORMAL | cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "        processing_times = collections.deque()\n",
    "        while True:\n",
    "            # grab the frame\n",
    "            frame1 = player.next()\n",
    "            if frame1 is None:\n",
    "                print(\"Source ended\")\n",
    "                break\n",
    "            else:    \n",
    "                #Filp the image otherwise the recognition result is wrong\n",
    "                frame = cv2.flip(frame1,1)\n",
    "                image_file = frame\n",
    "                test_image = image_preprocess(image_file,640)\n",
    "\n",
    "                # pdmodel might be dynamic shape, this will reshape based on the input\n",
    "                input_key = list(det_net.input_info.items())[0][0] # 'inputs'\n",
    "                det_net.reshape({input_key: test_image.shape})\n",
    "                det_exec_net = det_ie.load_network(det_net, 'CPU') \n",
    "\n",
    "                # measure processing time\n",
    "                start_time = time.time()\n",
    "                #perform the inference step\n",
    "                output = det_exec_net.infer({input_key: test_image})\n",
    "                stop_time = time.time()\n",
    "                result_ie = list(output.values())\n",
    "\n",
    "                # Postprocessing for Paddle Detection\n",
    "                ori_im = image_file.copy()\n",
    "                data = {'image': image_file}\n",
    "                data_resize = DetResizeForTest(data)\n",
    "                data_norm = NormalizeImage(data_resize)\n",
    "                data_list = []\n",
    "                keep_keys =  ['image', 'shape']\n",
    "                for key in keep_keys:\n",
    "                    data_list.append(data[key])\n",
    "                img, shape_list = data_list\n",
    "\n",
    "                shape_list = np.expand_dims(shape_list, axis=0)\n",
    "                pred = result_ie[0]      \n",
    "                if isinstance(pred, paddle.Tensor):\n",
    "                    pred = pred.numpy()\n",
    "                pred = pred[:, 0, :, :]\n",
    "                segmentation = pred > 0.3\n",
    "\n",
    "                boxes_batch = []\n",
    "                for batch_index in range(pred.shape[0]):\n",
    "                    src_h, src_w, ratio_h, ratio_w = shape_list[batch_index]\n",
    "                    mask = segmentation[batch_index]\n",
    "                    boxes, scores = boxes_from_bitmap(pred[batch_index], mask,src_w, src_h)\n",
    "                    boxes_batch.append({'points': boxes})\n",
    "                post_result = boxes_batch\n",
    "                dt_boxes = post_result[0]['points']\n",
    "\n",
    "                dt_boxes = filter_tag_det_res(dt_boxes, ori_im.shape)\n",
    "                #Draw boxes on detected text\n",
    "                src_im = draw_text_det_res(dt_boxes, image_file)\n",
    "\n",
    "                processing_times.append(stop_time - start_time)\n",
    "                # use processing times from last 200 frames\n",
    "                if len(processing_times) > 200:\n",
    "                    processing_times.popleft()\n",
    "                    \n",
    "                # mean processing time [ms]\n",
    "                processing_time_det = np.mean(processing_times) * 1000\n",
    "\n",
    "                #Preprocess detection results for recognition\n",
    "                dt_boxes = sorted_boxes(dt_boxes)\n",
    "                img_crop_list = []   \n",
    "                if dt_boxes != []:\n",
    "                    for bno in range(len(dt_boxes)):\n",
    "                        tmp_box = copy.deepcopy(dt_boxes[bno])\n",
    "                        img_crop = get_rotate_crop_image(ori_im, tmp_box)\n",
    "                        img_crop_list.append(img_crop)\n",
    "\n",
    "                    #Recognition starts from here\n",
    "                    img_num = len(img_crop_list)\n",
    "                    # Calculate the aspect ratio of all text bars\n",
    "                    width_list = []\n",
    "                    for img in img_crop_list:\n",
    "                        width_list.append(img.shape[1] / float(img.shape[0]))\n",
    "                    # Sorting can speed up the recognition process\n",
    "                    indices = np.argsort(np.array(width_list))\n",
    "                    rec_res = [['', 0.0]] * img_num\n",
    "                    rec_batch_num = 6\n",
    "                    batch_num = rec_batch_num\n",
    "                    rec_processing_times = 0\n",
    "\n",
    "                    #For each detected text box, run inference for text recognition\n",
    "                    for beg_img_no in range(0, img_num, batch_num):\n",
    "                        end_img_no = min(img_num, beg_img_no + batch_num)\n",
    "\n",
    "                        norm_img_batch = []\n",
    "                        max_wh_ratio = 0\n",
    "                        for ino in range(beg_img_no, end_img_no):\n",
    "                            h, w = img_crop_list[indices[ino]].shape[0:2]\n",
    "                            wh_ratio = w * 1.0 / h\n",
    "                            max_wh_ratio = max(max_wh_ratio, wh_ratio)\n",
    "                        for ino in range(beg_img_no, end_img_no):\n",
    "                            norm_img = resize_norm_img(img_crop_list[indices[ino]],max_wh_ratio)\n",
    "                            norm_img = norm_img[np.newaxis, :]\n",
    "                            norm_img_batch.append(norm_img)\n",
    "\n",
    "                        norm_img_batch = np.concatenate(norm_img_batch)\n",
    "                        norm_img_batch = norm_img_batch.copy()\n",
    "\n",
    "                        # pdmodel might be dynamic shape, this will reshape based on the input\n",
    "                        input_key = list(rec_net.input_info.items())[0][0] # 'inputs'\n",
    "                        rec_net.reshape({input_key: norm_img_batch.shape})\n",
    "                        #Load the Paddle recognition network on CPU\n",
    "                        rec_exec_net = rec_ie.load_network(rec_net, 'CPU') \n",
    "\n",
    "                        #Run inference for text recognition \n",
    "                        for index in range(len(norm_img_batch)):\n",
    "                            output = rec_exec_net.infer({input_key: norm_img_batch})\n",
    "                        result_ie = list(output.values())\n",
    "                        preds = result_ie[0]\n",
    "                        #Postprocessing recognition results\n",
    "                        postprocess_op = build_post_process(postprocess_params)\n",
    "                        rec_result = postprocess_op(preds)\n",
    "                        for rno in range(len(rec_result)):\n",
    "                            rec_res[indices[beg_img_no + rno]] = rec_result[rno]\n",
    "                    print(rec_res)\n",
    "                    \n",
    "                                                            \n",
    "                    if rec_res != []:\n",
    "                        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "                        boxes = dt_boxes\n",
    "                        txts = [rec_res[i][0] for i in range(len(rec_res))]\n",
    "                        scores = [rec_res[i][1] for i in range(len(rec_res))]\n",
    "\n",
    "                        draw_img = draw_ocr_box_txt(\n",
    "                                    image,\n",
    "                                    boxes,\n",
    "                                    txts,\n",
    "                                    scores,\n",
    "                                    drop_score=0.5,\n",
    "                                    font_path=\"simfang.ttf\")\n",
    "                        \n",
    "                        #Visualize Paddle detecion results\n",
    "                        _, f_width = draw_img.shape[:2]\n",
    "                        cv2.putText(img=draw_img, text=f\"OpenVINO running Inference time: {processing_time_det:.1f}ms\", org=(120, 140),\n",
    "                                fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=f_width / 1000,\n",
    "                                color=(0, 0, 255), thickness=1, lineType=cv2.LINE_AA)\n",
    "                        \n",
    "\n",
    "                        # use this workaround if there is flickering\n",
    "                        if use_popup: \n",
    "                            draw_img = cv2.cvtColor(draw_img, cv2.COLOR_RGB2BGR)\n",
    "                            cv2.imshow(winname=title, mat=draw_img)\n",
    "                            key = cv2.waitKey(1)\n",
    "                            # escape = 27\n",
    "                            if key == 27:\n",
    "                                break\n",
    "                        else:\n",
    "                            # encode numpy array to jpg\n",
    "                            _, encoded_img = cv2.imencode(ext=\".jpg\", img=draw_img,\n",
    "                                                                params=[cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "                            # create IPython image\n",
    "                            i = display.Image(data=encoded_img)\n",
    "                            # display the image in this notebook\n",
    "                            display.clear_output(wait=True)\n",
    "                            display.display(i)\n",
    "\n",
    "    # ctrl-c\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "    # any different error\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        # stop capturing\n",
    "        player.stop()\n",
    "        if use_popup:\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f8855f-418a-4bda-8799-0953dda895c5",
   "metadata": {},
   "source": [
    "## Run Live PaddleOCR with OpenVINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc274952-19aa-480d-ba50-a1146a89771b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('走进英国学生课堂的中国品牌航道', 0.87817115)]\n",
      "[('走进英国学生课堂的中国品牌教铺', 0.96182877)]\n",
      "[('以家F6力心', 0.25329956)]\n",
      "[('走进英国学生课堂的中国品牌教', 0.95429546)]\n",
      "[('走进英国学生课堂的中国品房取', 0.8463693)]\n",
      "[('走进英国学生课堂的中国品牌教', 0.8136431)]\n",
      "[('走进英国学生课堂的中国品费教请', 0.75422275)]\n",
      "[('走进英国学生课量的中国品具', 0.8255894)]\n",
      "[('走进英国学生课堂的中国品牌教', 0.8335849)]\n",
      "[('走进英国学生课堂的中国品自教', 0.83130133)]\n",
      "[('走进英国学生调堂的中国品国教', 0.7722003)]\n",
      "[('走进英国学生课堂的中国品房教', 0.85407174)]\n",
      "[('走进英国学生课堂的中国品牌教', 0.8045702)]\n",
      "[('走进英团学生课堂的中国品具教', 0.78325015)]\n",
      "[('走进英国学生退育', 0.52810043)]\n",
      "[('特', 0.2024523)]\n",
      "[('中国品牌教锁', 0.83820266), ('东师大版', 0.99542165), ('甲店', 0.7678734)]\n",
      "[('汉堂的中国品牌教辅', 0.87584615), ('东师大版', 0.99855316), ('甲体', 0.47539425)]\n",
      "[('汉堂的中国品牌教辅', 0.8204628), ('东师大版', 0.99854726), ('甲体', 0.5809884)]\n",
      "[('课体', 0.5682919)]\n",
      "[('自店', 0.17936066)]\n",
      "[('国学生课堂的中国品牌教辅', 0.86330575), ('口华东师大版', 0.9212818), ('课炼', 0.57764995)]\n",
      "[('四华东师大版', 0.87542534), ('课练', 0.7643785)]\n",
      "[('走进英国学生课堂的中国品牌教辅', 0.9429133), ('华东师大版', 0.9980751), ('甲', 0.7323788), ('法', 0.13929339)]\n",
      "[('华东师大版', 0.99856055), ('课法', 0.7751006)]\n",
      "[('华东师大版', 0.99908084), ('里法', 0.7112348)]\n",
      "[('四华东师大版', 0.89812136), ('课法', 0.34899655)]\n",
      "[('汉促高能力为1标 助影道建理题个楼', 0.49714234), ('华东师大版', 0.9987591), ('课体', 0.606691)]\n",
      "[('走进英国学生课堂的中国品牌教辅', 0.95992315), ('华东师大版', 0.9986086), ('课炼', 0.6683807)]\n",
      "[('走途英国学生课堂的中国品牌教辅', 0.93842435), ('华东师大版', 0.9984754), ('课一体', 0.7264394)]\n",
      "[('走进英国学生课堂的中国品牌教辅', 0.94730955), ('华东师大版', 0.99734056)]\n",
      "[('走进英国学生课堂的中国品牌教辅', 0.99112505), ('专为心似费高能力为门标 助你迈进想学校', 0.6949115), ('华东师大版', 0.998816), ('六', 0.23003866)]\n",
      "[('走进英国学生课堂的中国品牌教辅', 0.9894785), ('为心以爱高能力为1标 助你边进理融学校', 0.60969687), ('华东师大版', 0.9978903), ('福六', 0.13481873)]\n",
      "[('走进英国学生课堂的中国品牌教辅', 0.96333057), ('音食为心以爱高能力为1标 防你近进印想校', 0.56547445), ('华东师大版', 0.99879897), ('甲点', 0.1887535)]\n",
      "[('走进英国学生课堂的中国品牌教辅', 0.9661417), ('限业专心以提卤能力为1标 助你边进理您学校', 0.5191977), ('华东师大版', 0.9989794), ('甲店', 0.47928166)]\n",
      "[('走进英国学生课堂的中国品牌教辅', 0.9198668), ('鲁为心以提高能力为旧标 助你迈进理想学校', 0.7102345), ('华东师大版', 0.9984927), ('迎内', 0.3394165)]\n"
     ]
    }
   ],
   "source": [
    "run_paddle_ocr(source=0, flip=True, use_popup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6c9d077-70df-4a28-a372-7ee5168f6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test OCR results on uploaded video file\n",
    "\n",
    "#video_file = \"test1.mp4\"\n",
    "#source = video_file\n",
    "#player = utils.VideoPlayer(source=source, flip=False, fps=30)\n",
    "#run_paddle_ocr(source=source, flip=True, use_popup=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
